{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/jane-street-market-prediction/example_sample_submission.csv\n/kaggle/input/jane-street-market-prediction/features.csv\n/kaggle/input/jane-street-market-prediction/example_test.csv\n/kaggle/input/jane-street-market-prediction/train.csv\n/kaggle/input/jane-street-market-prediction/janestreet/competition.cpython-37m-x86_64-linux-gnu.so\n/kaggle/input/jane-street-market-prediction/janestreet/__init__.py\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/jane-street-market-prediction/train.csv')\ntrain = train.query('date > 85').reset_index(drop = True) \ntrain = train[train['weight'] != 0]","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fill_mode = lambda col: col.fillna(col.mode()[0])\ntrain = train.apply(fill_mode, axis=0)\ntrain.isna().sum()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"date           0\nweight         0\nresp_1         0\nresp_2         0\nresp_3         0\n              ..\nfeature_126    0\nfeature_127    0\nfeature_128    0\nfeature_129    0\nts_id          0\nLength: 138, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['action'] = ((train['weight'].values * \\\n                         (train['resp_1'].values + \\\n                          train['resp_2'].values + train['resp_3'].values + train['resp_4'].values + train['resp'].values))/5 > 0).astype('int')","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['resp', 'resp_1', 'resp_2', 'resp_3', 'resp_4'], axis=1)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['date', 'ts_id', 'action'], axis=1)\ny = train['action']","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import QuantileTransformer\n\nquant_transf = QuantileTransformer(n_quantiles=100, output_distribution='normal')\nX_norm = quant_transf.fit_transform(X)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=60)\npca.fit(X_norm)","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"PCA(n_components=60)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_pca = pca.transform(X_norm)\ndf_X_pca = pd.DataFrame(X_pca)","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_X_pca","execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"                0          1         2         3         4         5   \\\n0        10.267772  16.946523 -1.331063 -5.670721 -4.093065  2.104919   \n1        -6.347576  13.478861  6.620328 -3.594931 -5.978475  3.056489   \n2         8.932523  18.439425  0.463090 -1.298187 -2.387967  1.721530   \n3        -4.202906  12.185362  8.171649 -3.729960 -6.939321  3.266822   \n4        -4.196369  10.527558  9.632615 -5.211299 -6.616397  3.559874   \n...            ...        ...       ...       ...       ...       ...   \n1571410  -7.383487  -8.093775  1.863693 -1.093240 -2.657842  3.243292   \n1571411  11.933524  -5.057887 -3.671960 -0.338875  4.053339 -1.803195   \n1571412  -4.419997  -4.594033  1.650150 -0.727765 -0.990756  3.741446   \n1571413 -10.159801  -1.499152 -3.187130  1.567313  0.025382 -0.223769   \n1571414  -2.997294 -11.617262  7.838755  2.195159 -5.433748  7.375299   \n\n               6         7         8         9   ...        50        51  \\\n0        0.566892 -4.250220 -1.921255  0.970606  ...  0.366612  0.031499   \n1       -0.094001 -3.234973 -2.120153 -1.623328  ... -0.062853 -0.215289   \n2        1.101011 -3.905756 -1.883096  0.154013  ... -0.216718 -0.394815   \n3        3.768947 -2.715431 -3.053356  0.807371  ...  0.282798 -0.023699   \n4        1.816287 -2.397273 -2.785546 -0.278132  ... -0.452119  0.169474   \n...           ...       ...       ...       ...  ...       ...       ...   \n1571410 -2.186097  3.098878  0.466389  2.547661  ...  0.506802  0.187615   \n1571411 -0.185232  4.254357 -1.934252  1.895291  ... -0.718351 -1.359395   \n1571412  4.614244  1.951358 -1.840219  2.199059  ... -0.065476  0.542272   \n1571413  1.413488  3.043434  0.410100  0.457263  ...  1.040076 -0.318974   \n1571414  3.348766  1.861883 -1.686998 -3.711594  ...  0.205101  0.602285   \n\n               52        53        54        55        56        57        58  \\\n0       -0.688510  0.254045  0.350635 -0.021549 -0.095333 -0.499643 -0.262423   \n1       -1.132494  0.914764  0.338504 -0.019463  0.682655  0.950265  0.047911   \n2       -0.429627 -0.264379  0.226834  0.074856 -0.164028 -0.516284 -0.233366   \n3       -1.064348  0.162919 -0.303998 -0.043396  0.524311  0.960083 -0.227284   \n4       -0.426684  0.320497 -0.495610 -0.127310  0.670623  1.439441  0.135713   \n...           ...       ...       ...       ...       ...       ...       ...   \n1571410  0.048508  0.136285  0.628497  0.230144 -0.389141  0.279421  0.305769   \n1571411  0.409063  0.126245  0.251997 -0.120654  0.155802  0.284568  0.034169   \n1571412  0.255529  0.299357 -0.388853  0.255215 -0.408657 -0.312628  0.048616   \n1571413 -1.103048  0.101136  0.684958  0.126496 -0.608576  0.106263  0.116390   \n1571414 -0.027727  0.113143  0.068738 -0.451104 -0.447396  0.219586 -0.425874   \n\n               59  \n0        0.137681  \n1       -0.083753  \n2        0.135736  \n3        0.119126  \n4       -0.053754  \n...           ...  \n1571410  0.233719  \n1571411 -0.161152  \n1571412  0.216179  \n1571413  0.428562  \n1571414  0.363853  \n\n[1571415 rows x 60 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n      <th>58</th>\n      <th>59</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.267772</td>\n      <td>16.946523</td>\n      <td>-1.331063</td>\n      <td>-5.670721</td>\n      <td>-4.093065</td>\n      <td>2.104919</td>\n      <td>0.566892</td>\n      <td>-4.250220</td>\n      <td>-1.921255</td>\n      <td>0.970606</td>\n      <td>...</td>\n      <td>0.366612</td>\n      <td>0.031499</td>\n      <td>-0.688510</td>\n      <td>0.254045</td>\n      <td>0.350635</td>\n      <td>-0.021549</td>\n      <td>-0.095333</td>\n      <td>-0.499643</td>\n      <td>-0.262423</td>\n      <td>0.137681</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-6.347576</td>\n      <td>13.478861</td>\n      <td>6.620328</td>\n      <td>-3.594931</td>\n      <td>-5.978475</td>\n      <td>3.056489</td>\n      <td>-0.094001</td>\n      <td>-3.234973</td>\n      <td>-2.120153</td>\n      <td>-1.623328</td>\n      <td>...</td>\n      <td>-0.062853</td>\n      <td>-0.215289</td>\n      <td>-1.132494</td>\n      <td>0.914764</td>\n      <td>0.338504</td>\n      <td>-0.019463</td>\n      <td>0.682655</td>\n      <td>0.950265</td>\n      <td>0.047911</td>\n      <td>-0.083753</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.932523</td>\n      <td>18.439425</td>\n      <td>0.463090</td>\n      <td>-1.298187</td>\n      <td>-2.387967</td>\n      <td>1.721530</td>\n      <td>1.101011</td>\n      <td>-3.905756</td>\n      <td>-1.883096</td>\n      <td>0.154013</td>\n      <td>...</td>\n      <td>-0.216718</td>\n      <td>-0.394815</td>\n      <td>-0.429627</td>\n      <td>-0.264379</td>\n      <td>0.226834</td>\n      <td>0.074856</td>\n      <td>-0.164028</td>\n      <td>-0.516284</td>\n      <td>-0.233366</td>\n      <td>0.135736</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-4.202906</td>\n      <td>12.185362</td>\n      <td>8.171649</td>\n      <td>-3.729960</td>\n      <td>-6.939321</td>\n      <td>3.266822</td>\n      <td>3.768947</td>\n      <td>-2.715431</td>\n      <td>-3.053356</td>\n      <td>0.807371</td>\n      <td>...</td>\n      <td>0.282798</td>\n      <td>-0.023699</td>\n      <td>-1.064348</td>\n      <td>0.162919</td>\n      <td>-0.303998</td>\n      <td>-0.043396</td>\n      <td>0.524311</td>\n      <td>0.960083</td>\n      <td>-0.227284</td>\n      <td>0.119126</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-4.196369</td>\n      <td>10.527558</td>\n      <td>9.632615</td>\n      <td>-5.211299</td>\n      <td>-6.616397</td>\n      <td>3.559874</td>\n      <td>1.816287</td>\n      <td>-2.397273</td>\n      <td>-2.785546</td>\n      <td>-0.278132</td>\n      <td>...</td>\n      <td>-0.452119</td>\n      <td>0.169474</td>\n      <td>-0.426684</td>\n      <td>0.320497</td>\n      <td>-0.495610</td>\n      <td>-0.127310</td>\n      <td>0.670623</td>\n      <td>1.439441</td>\n      <td>0.135713</td>\n      <td>-0.053754</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1571410</th>\n      <td>-7.383487</td>\n      <td>-8.093775</td>\n      <td>1.863693</td>\n      <td>-1.093240</td>\n      <td>-2.657842</td>\n      <td>3.243292</td>\n      <td>-2.186097</td>\n      <td>3.098878</td>\n      <td>0.466389</td>\n      <td>2.547661</td>\n      <td>...</td>\n      <td>0.506802</td>\n      <td>0.187615</td>\n      <td>0.048508</td>\n      <td>0.136285</td>\n      <td>0.628497</td>\n      <td>0.230144</td>\n      <td>-0.389141</td>\n      <td>0.279421</td>\n      <td>0.305769</td>\n      <td>0.233719</td>\n    </tr>\n    <tr>\n      <th>1571411</th>\n      <td>11.933524</td>\n      <td>-5.057887</td>\n      <td>-3.671960</td>\n      <td>-0.338875</td>\n      <td>4.053339</td>\n      <td>-1.803195</td>\n      <td>-0.185232</td>\n      <td>4.254357</td>\n      <td>-1.934252</td>\n      <td>1.895291</td>\n      <td>...</td>\n      <td>-0.718351</td>\n      <td>-1.359395</td>\n      <td>0.409063</td>\n      <td>0.126245</td>\n      <td>0.251997</td>\n      <td>-0.120654</td>\n      <td>0.155802</td>\n      <td>0.284568</td>\n      <td>0.034169</td>\n      <td>-0.161152</td>\n    </tr>\n    <tr>\n      <th>1571412</th>\n      <td>-4.419997</td>\n      <td>-4.594033</td>\n      <td>1.650150</td>\n      <td>-0.727765</td>\n      <td>-0.990756</td>\n      <td>3.741446</td>\n      <td>4.614244</td>\n      <td>1.951358</td>\n      <td>-1.840219</td>\n      <td>2.199059</td>\n      <td>...</td>\n      <td>-0.065476</td>\n      <td>0.542272</td>\n      <td>0.255529</td>\n      <td>0.299357</td>\n      <td>-0.388853</td>\n      <td>0.255215</td>\n      <td>-0.408657</td>\n      <td>-0.312628</td>\n      <td>0.048616</td>\n      <td>0.216179</td>\n    </tr>\n    <tr>\n      <th>1571413</th>\n      <td>-10.159801</td>\n      <td>-1.499152</td>\n      <td>-3.187130</td>\n      <td>1.567313</td>\n      <td>0.025382</td>\n      <td>-0.223769</td>\n      <td>1.413488</td>\n      <td>3.043434</td>\n      <td>0.410100</td>\n      <td>0.457263</td>\n      <td>...</td>\n      <td>1.040076</td>\n      <td>-0.318974</td>\n      <td>-1.103048</td>\n      <td>0.101136</td>\n      <td>0.684958</td>\n      <td>0.126496</td>\n      <td>-0.608576</td>\n      <td>0.106263</td>\n      <td>0.116390</td>\n      <td>0.428562</td>\n    </tr>\n    <tr>\n      <th>1571414</th>\n      <td>-2.997294</td>\n      <td>-11.617262</td>\n      <td>7.838755</td>\n      <td>2.195159</td>\n      <td>-5.433748</td>\n      <td>7.375299</td>\n      <td>3.348766</td>\n      <td>1.861883</td>\n      <td>-1.686998</td>\n      <td>-3.711594</td>\n      <td>...</td>\n      <td>0.205101</td>\n      <td>0.602285</td>\n      <td>-0.027727</td>\n      <td>0.113143</td>\n      <td>0.068738</td>\n      <td>-0.451104</td>\n      <td>-0.447396</td>\n      <td>0.219586</td>\n      <td>-0.425874</td>\n      <td>0.363853</td>\n    </tr>\n  </tbody>\n</table>\n<p>1571415 rows × 60 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the variance in each component\n\ny_variance = pca.explained_variance_ratio_\nprint(y_variance)\nvariance_sum = np.sum(y_variance)\nvariance_sum","execution_count":37,"outputs":[{"output_type":"stream","text":"[0.35015802 0.11083169 0.08052959 0.07169189 0.04331699 0.03749399\n 0.0298198  0.02450167 0.01958024 0.018858   0.01673821 0.01480896\n 0.01434448 0.01305356 0.01169462 0.00972094 0.00941423 0.00925625\n 0.00889918 0.00767614 0.0069492  0.0069038  0.00672059 0.00587844\n 0.00556627 0.00468511 0.00450775 0.00427327 0.00382346 0.00357803\n 0.00345269 0.00259438 0.00232548 0.00228062 0.00225987 0.00220166\n 0.00207961 0.00205003 0.00174569 0.00149185 0.00134726 0.00128668\n 0.00118897 0.00118005 0.00116698 0.0010843  0.00099359 0.00092172\n 0.00090574 0.00085781 0.00075814 0.00072046 0.00065098 0.00062772\n 0.00055402 0.00053034 0.00046657 0.00046038 0.00038923 0.00038845]\n","name":"stdout"},{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"0.99423566734869"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}