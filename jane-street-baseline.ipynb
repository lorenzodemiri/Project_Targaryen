{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":12,"outputs":[{"output_type":"stream","text":"/kaggle/input/jane-street-market-prediction/example_sample_submission.csv\n/kaggle/input/jane-street-market-prediction/features.csv\n/kaggle/input/jane-street-market-prediction/example_test.csv\n/kaggle/input/jane-street-market-prediction/train.csv\n/kaggle/input/jane-street-market-prediction/janestreet/competition.cpython-37m-x86_64-linux-gnu.so\n/kaggle/input/jane-street-market-prediction/janestreet/__init__.py\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Importing train data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/jane-street-market-prediction/train.csv\")","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"   date     weight    resp_1    resp_2    resp_3    resp_4      resp  \\\n0     0   0.000000  0.009916  0.014079  0.008773  0.001390  0.006270   \n1     0  16.673515 -0.002828 -0.003226 -0.007319 -0.011114 -0.009792   \n2     0   0.000000  0.025134  0.027607  0.033406  0.034380  0.023970   \n3     0   0.000000 -0.004730 -0.003273 -0.000461 -0.000476 -0.003200   \n4     0   0.138531  0.001252  0.002165 -0.001215 -0.006219 -0.002604   \n\n   feature_0  feature_1  feature_2  ...  feature_121  feature_122  \\\n0          1  -1.872746  -2.191242  ...          NaN     1.168391   \n1         -1  -1.349537  -1.704709  ...          NaN    -1.178850   \n2         -1   0.812780  -0.256156  ...          NaN     6.115747   \n3         -1   1.174378   0.344640  ...          NaN     2.838853   \n4          1  -3.172026  -3.093182  ...          NaN     0.344850   \n\n   feature_123  feature_124  feature_125  feature_126  feature_127  \\\n0     8.313583     1.782433    14.018213     2.653056    12.600292   \n1     1.777472    -0.915458     2.831612    -1.417010     2.297459   \n2     9.667908     5.542871    11.671595     7.281757    10.060014   \n3     0.499251     3.033732     1.513488     4.397532     1.266037   \n4     4.101145     0.614252     6.623456     0.800129     5.233243   \n\n   feature_128  feature_129  ts_id  \n0     2.301488    11.445807      0  \n1    -1.304614     1.898684      1  \n2     6.638248     9.427299      2  \n3     3.856384     1.013469      3  \n4     0.362636     3.926633      4  \n\n[5 rows x 138 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>weight</th>\n      <th>resp_1</th>\n      <th>resp_2</th>\n      <th>resp_3</th>\n      <th>resp_4</th>\n      <th>resp</th>\n      <th>feature_0</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>...</th>\n      <th>feature_121</th>\n      <th>feature_122</th>\n      <th>feature_123</th>\n      <th>feature_124</th>\n      <th>feature_125</th>\n      <th>feature_126</th>\n      <th>feature_127</th>\n      <th>feature_128</th>\n      <th>feature_129</th>\n      <th>ts_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.009916</td>\n      <td>0.014079</td>\n      <td>0.008773</td>\n      <td>0.001390</td>\n      <td>0.006270</td>\n      <td>1</td>\n      <td>-1.872746</td>\n      <td>-2.191242</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.168391</td>\n      <td>8.313583</td>\n      <td>1.782433</td>\n      <td>14.018213</td>\n      <td>2.653056</td>\n      <td>12.600292</td>\n      <td>2.301488</td>\n      <td>11.445807</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>16.673515</td>\n      <td>-0.002828</td>\n      <td>-0.003226</td>\n      <td>-0.007319</td>\n      <td>-0.011114</td>\n      <td>-0.009792</td>\n      <td>-1</td>\n      <td>-1.349537</td>\n      <td>-1.704709</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>-1.178850</td>\n      <td>1.777472</td>\n      <td>-0.915458</td>\n      <td>2.831612</td>\n      <td>-1.417010</td>\n      <td>2.297459</td>\n      <td>-1.304614</td>\n      <td>1.898684</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.025134</td>\n      <td>0.027607</td>\n      <td>0.033406</td>\n      <td>0.034380</td>\n      <td>0.023970</td>\n      <td>-1</td>\n      <td>0.812780</td>\n      <td>-0.256156</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>6.115747</td>\n      <td>9.667908</td>\n      <td>5.542871</td>\n      <td>11.671595</td>\n      <td>7.281757</td>\n      <td>10.060014</td>\n      <td>6.638248</td>\n      <td>9.427299</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>-0.004730</td>\n      <td>-0.003273</td>\n      <td>-0.000461</td>\n      <td>-0.000476</td>\n      <td>-0.003200</td>\n      <td>-1</td>\n      <td>1.174378</td>\n      <td>0.344640</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.838853</td>\n      <td>0.499251</td>\n      <td>3.033732</td>\n      <td>1.513488</td>\n      <td>4.397532</td>\n      <td>1.266037</td>\n      <td>3.856384</td>\n      <td>1.013469</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.138531</td>\n      <td>0.001252</td>\n      <td>0.002165</td>\n      <td>-0.001215</td>\n      <td>-0.006219</td>\n      <td>-0.002604</td>\n      <td>1</td>\n      <td>-3.172026</td>\n      <td>-3.093182</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.344850</td>\n      <td>4.101145</td>\n      <td>0.614252</td>\n      <td>6.623456</td>\n      <td>0.800129</td>\n      <td>5.233243</td>\n      <td>0.362636</td>\n      <td>3.926633</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 138 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":16,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2390491 entries, 0 to 2390490\nColumns: 138 entries, date to ts_id\ndtypes: float64(135), int64(3)\nmemory usage: 2.5 GB\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Checking nulls in train data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"nulls = train.columns[train.isna().any()].tolist()\ntrain_null = train[nulls]\nnulls, len(nulls)","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"(['feature_3',\n  'feature_4',\n  'feature_7',\n  'feature_8',\n  'feature_9',\n  'feature_10',\n  'feature_11',\n  'feature_12',\n  'feature_13',\n  'feature_14',\n  'feature_15',\n  'feature_16',\n  'feature_17',\n  'feature_18',\n  'feature_19',\n  'feature_20',\n  'feature_21',\n  'feature_22',\n  'feature_23',\n  'feature_24',\n  'feature_25',\n  'feature_26',\n  'feature_27',\n  'feature_28',\n  'feature_29',\n  'feature_30',\n  'feature_31',\n  'feature_32',\n  'feature_33',\n  'feature_34',\n  'feature_35',\n  'feature_36',\n  'feature_44',\n  'feature_45',\n  'feature_55',\n  'feature_56',\n  'feature_58',\n  'feature_59',\n  'feature_72',\n  'feature_73',\n  'feature_74',\n  'feature_75',\n  'feature_76',\n  'feature_78',\n  'feature_79',\n  'feature_80',\n  'feature_81',\n  'feature_82',\n  'feature_84',\n  'feature_85',\n  'feature_86',\n  'feature_87',\n  'feature_88',\n  'feature_90',\n  'feature_91',\n  'feature_92',\n  'feature_93',\n  'feature_94',\n  'feature_96',\n  'feature_97',\n  'feature_98',\n  'feature_99',\n  'feature_100',\n  'feature_102',\n  'feature_103',\n  'feature_104',\n  'feature_105',\n  'feature_106',\n  'feature_108',\n  'feature_109',\n  'feature_110',\n  'feature_111',\n  'feature_112',\n  'feature_114',\n  'feature_115',\n  'feature_116',\n  'feature_117',\n  'feature_118',\n  'feature_120',\n  'feature_121',\n  'feature_122',\n  'feature_123',\n  'feature_124',\n  'feature_125',\n  'feature_126',\n  'feature_127',\n  'feature_128',\n  'feature_129'],\n 88)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fig = plt.figure(figsize = (30,50))\n#ax = fig.gca()\n#train_null.hist(ax = ax, bins=30)","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Filling the nulls with mode**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fill_mode = lambda col: col.fillna(col.mode()[0])","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.apply(fill_mode, axis=0)\ntrain.isna().sum()","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"date           0\nweight         0\nresp_1         0\nresp_2         0\nresp_3         0\n              ..\nfeature_126    0\nfeature_127    0\nfeature_128    0\nfeature_129    0\nts_id          0\nLength: 138, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Checking cumulative sum of different resp over time**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#fig = plt.figure(figsize=(16,6))\n#ax = plt.subplot(1,1,1)\n#train.groupby('date')[['resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp']].sum().cumsum().plot(ax=ax)\n#plt.title('Cumulative Sum of Different RESP\\'s',fontsize=18)\n#plt.xlabel('Date',fontsize=14)\n#plt.axvspan(0,92,linestyle=':',linewidth=2,label='first 92 days',color='darkorange',alpha=.2)\n#plt.legend(fontsize=12,ncol=3,loc=2);","execution_count":21,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Since we have an high increase in the first 92 days, it could be a period of assestment of the model so we can drop them**<br>\n**We also drop the rows that have 'wheight' = 0, since they will not be used for evaluation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.query('date > 92')\ntrain = train[train['weight'] > 0]\ntrain.info()","execution_count":22,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1549854 entries, 553726 to 2390489\nColumns: 138 entries, date to ts_id\ndtypes: float64(135), int64(3)\nmemory usage: 1.6 GB\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**We define a target column ('Action') multypling the weight by the average of all the resp**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['action'] = ((train['weight'].values * \\\n                         (train['resp_1'] + train['resp_2'] + train['resp_3'] + train['resp_4'] + train['resp']).values)/5 > 0).astype('int')\ntrain['action']","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"553726     1\n553728     1\n553729     0\n553730     1\n553732     1\n          ..\n2390444    0\n2390446    0\n2390478    0\n2390481    0\n2390489    0\nName: action, Length: 1549854, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Since we summarize all the resp in the action column, we can drop them**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['resp', 'resp_1', 'resp_2', 'resp_3', 'resp_4'], axis=1)","execution_count":24,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Defining X and Y**<br>\nWe keep date below 450 to train, and above to validate"},{"metadata":{"trusted":true},"cell_type":"code","source":"#X = train.drop(['date', 'ts_id', 'action'], axis=1)\nX_train = train.loc[train.date < 425].drop(['date', 'ts_id', 'action'], axis=1)\nX_val = train.loc[train.date >= 425].drop(['date', 'ts_id', 'action'], axis=1) \n#y = train['action']\ny_train = train.loc[train.date < 425]['action']\ny_val = train.loc[train.date >= 425]['action']\n","execution_count":25,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**scale with quantile transformer** n_quantiles = 100, output_distribution = normal"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import QuantileTransformer\n\nquant_transf = QuantileTransformer(n_quantiles=100, output_distribution='normal')\nX_train = quant_transf.fit_transform(X_train)\nX_val = quant_transf.transform(X_val)","execution_count":26,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Getting prediction with a base model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\nsvc = LinearSVC()\n\nsvc.fit(X_train, y_train)","execution_count":28,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n","name":"stderr"},{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"LinearSVC()"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = svc.predict(X_val)\nsvc.score(X_val, y_val)","execution_count":31,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [339964, 1209890]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-5b8bb134098e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \"\"\"\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 256\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [339964, 1209890]"]}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}